# THIS FILE IS USED BY buildFlows.sh and loads as a shell script env variable by simply calling source config.env

COMMON_ADL_ACCOUNT="example.dfs.core.windows.net"

RAW_ADL_ACCOUNT="example.dfs.core.windows.net"
RAW_ADL_CONTAINER="dev-raw"
RAW_ADL_FOLDER="Kanari_POC_MVP/Upload_Data"
RAW_PREPROCESSOR_SINCE="202007"
RAW_PREFETCH_FROM="202007"
RAW_PREFETCH_TO="20211130"

PREP_ADL_ACCOUNT="example.dfs.core.windows.net"
PREP_ADL_CONTAINER="dev-prep"
PREP_ADL_FOLDER="Kanari_POC_MVP/Upload_Data"

EVENTS_ADL_ACCOUNT="example.dfs.core.windows.net"
EVENTS_ADL_CONTAINER="dev-biz-events"
EVENTS_ADL_FOLDER="Kanari_POC_MVP"

# location can be base64 or hdfs
#   if base64, use UBER_OBJECT_RULE_SCRIPT to embed python file into json file
#   if hdfs, use UBER_OBJECT_RULE_PATH to be the abfs path to the .py file
UBER_OBJECT_RULE_LOCATION=hdfs
UBER_OBJECT_RULE_PATH="abfs://dev-biz-events@kdpoc2.dfs.core.windows.net/rules/uber_with_rules.py"
UBER_OBJECT_RULE_SCRIPT="./fromEvents/uber_with_rules.py"


SQL_URL="jdbc:sqlserver://examplems.database.windows.net:1433;database=examplems;"
SQL_USERNAME="xxxx"
SQL_PASSWORD="yyy"

AZ_SUBSCRIPTION_ID=b16e977c-7715-4783-9b76-790c9a7c1aef
AZ_WORKSPACE=examplesynapse
AZ_POOL=examplesparkpool
AZ_EXECSIZE=Small
AZ_EXECCOUNT=2
AZ_COMMONJAR_PATH=abfss://examplesynapse-fs@example.dfs.core.windows.net/bst/common/
AZ_BSTJAR=abfss://examplesynapse-fs@example.dfs.core.windows.net/bst/latest/obspark-0.4.11-SNAPSHOT_hdp3.1.jar
